expid,task,model,learning_rate,batch_size,epochs,dropout,optimizer,accuracy,f1,loss,train_time
exp_001,MNLI,bert-base,2e-5,16,3,0.1,AdamW,0.842,0.835,0.395,12.4
exp_002,MNLI,bert-base,3e-5,32,3,0.1,AdamW,0.847,0.841,0.382,10.8
exp_003,MNLI,bert-large,2e-5,16,4,0.1,AdamW,0.855,0.851,0.374,15.6
exp_004,QQP,bert-base,2e-5,16,3,0.1,AdamW,0.902,0.896,0.270,9.5
exp_005,QQP,bert-base,3e-5,32,3,0.1,AdamW,0.908,0.903,0.256,8.9
exp_006,QQP,bert-large,2e-5,32,4,0.1,AdamW,0.914,0.910,0.243,13.7
exp_007,SST-2,roberta-base,1e-5,16,3,0.1,AdamW,0.926,0.924,0.214,7.4
exp_008,SST-2,roberta-base,2e-5,32,4,0.1,AdamW,0.932,0.930,0.205,6.9
exp_009,SST-2,roberta-large,1e-5,16,3,0.1,AdamW,0.944,0.943,0.193,11.2
exp_010,QNLI,deberta-base,2e-5,32,3,0.1,AdamW,0.918,0.915,0.228,10.1
exp_011,QNLI,deberta-base,3e-5,16,3,0.1,AdamW,0.922,0.918,0.221,10.5
exp_012,QNLI,deberta-large,2e-5,32,4,0.1,AdamW,0.931,0.928,0.209,14.8
exp_013,RTE,bert-base,2e-5,16,3,0.1,AdamW,0.732,0.725,0.623,4.7
exp_014,RTE,roberta-base,2e-5,16,4,0.1,AdamW,0.751,0.748,0.591,5.1
exp_015,RTE,deberta-base,1e-5,32,4,0.1,AdamW,0.766,0.760,0.562,6.3
exp_016,MNLI,roberta-base,2e-5,32,3,0.1,AdamW,0.858,0.853,0.362,11.4
exp_017,QQP,deberta-base,2e-5,32,3,0.1,AdamW,0.919,0.915,0.236,12.8
exp_018,SST-2,deberta-large,1e-5,16,4,0.1,AdamW,0.950,0.948,0.182,13.9

